{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BWxFkG9F1ZR3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\"\"\" # Set Spark version\n",
        "spark_version = 'spark-3.5.2'\n",
        "os.environ['SPARK_VERSION'] = spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-23\"\n",
        "os.environ[\"SPARK_HOME\"] = \"C:\\\\spark-3.5.3-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\"\"\"\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lsmPjpmO7db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zaZmul_IrL5s"
      },
      "outputs": [],
      "source": [
        "# Start a Spark session\n",
        "spark = SparkSession.builder.appName(\"CoffeeRatings\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ_OsAwk9V-s",
        "outputId": "0f81ab0f-0314-4390-fb58-7e42d16c3656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+--------------------+----------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+---------+--------------------+--------------------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+\n",
            "|                name|                slug|rating|             roaster|        location|              origin|       roast|cost_12oz|review_date|aroma|acid|body|flavor|aftertaste|with_milk|              desc_1|              desc_2|              desc_3|Location_Latitude|Location_Longitude|Origin_Latitude|Origin_Longitude|Blend/Single Origin|      desc_1_cleaned|\n",
            "+--------------------+--------------------+------+--------------------+----------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+---------+--------------------+--------------------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+\n",
            "|GW01 Finca Sophia...|https://www.coffe...|    96|           GK Coffee|   Yilan, Taiwan|Nueva Suiza, Chir...|Medium-Light|  2721.55|     20-Nov|   20|  20|  18|    20|        18|     NULL|Graceful, polishe...|This exceptional ...|This Best of Pana...|       24.7519538|       121.7533344|      8.8536305|     -82.5974465|      Single Origin|graceful polished...|\n",
            "|Panama Carmen Gei...|https://www.coffe...|    90|           GK Coffee|   Yilan, Taiwan|  Paso Ancho, Panama|       Light|  1360.78|     23-Oct|   18|  18|  18|    18|        18|     NULL|Multi-layered, su...|Produced by Carlo...|An elegant washed...|       24.7519538|       121.7533344|      8.8162993|     -82.6186456|      Single Origin|multilayered subt...|\n",
            "|Ninety Plus Panam...|https://www.coffe...|    90|Plat Coffee Roastery|Hong Kong, China|Chiriqui Province...|Medium-Light|  1360.78|     21-Nov|   18|  18|  18|    18|        18|     NULL|Elegantly fruit-t...|Produced by Josep...|A distinctively c...|       22.2793278|       114.1628131|       8.758489|      -81.595259|      Single Origin|elegantly fruitto...|\n",
            "|Panama Mokkita Na...|https://www.coffe...|    92|   Paradise Roasters|    Hilo, Hawaii|     Boquete, Panama|       Light|      750|     24-Feb|   18|  18|  18|    20|        18|     NULL|Richly floral, fr...|Produced by the G...|Spice-toned flora...|       19.7073734|        -155.08158|      8.7380282|     -82.4294739|      Single Origin|fruitsaturated wi...|\n",
            "|   Mama Cata Mokkita|https://www.coffe...|    90|          Cafe Unido|Washington, D.C.|Boquete growing r...|Medium-Light|      450|     21-Sep|   18|  18|  18|    18|        18|     NULL|Rich, resonant, l...|Produced by the G...|Mokkita, a rare s...|       38.8950368|       -77.0365427|      8.7692451|    -82.43063508|      Single Origin|rich lyrically wh...|\n",
            "+--------------------+--------------------+------+--------------------+----------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+---------+--------------------+--------------------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset into a Spark DataFrame\n",
        "file_name = '/content/drive/MyDrive/Coffee practice/coffee_lat_lon_updated_cleaned(latest2).csv'  # The name should match the uploaded file\n",
        "df_spark = spark.read.csv(file_name, header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows to confirm the DataFrame is loaded\n",
        "df_spark.show(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exGQlu3MrbRA",
        "outputId": "ab9f1918-5193-4156-90d9-5f80c247d322"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PTePlUvPgzo",
        "outputId": "93eedcd8-539c-48ca-8905-347e93b01f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+\n",
            "|                name|                slug|             roaster|            location|              origin|       roast|              desc_1|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+\n",
            "|GW01 Finca Sophia...|https://www.coffe...|           GK Coffee|       Yilan, Taiwan|Nueva Suiza, Chir...|Medium-Light|Graceful, polishe...|\n",
            "|Panama Carmen Gei...|https://www.coffe...|           GK Coffee|       Yilan, Taiwan|  Paso Ancho, Panama|       Light|Multi-layered, su...|\n",
            "|Ninety Plus Panam...|https://www.coffe...|Plat Coffee Roastery|    Hong Kong, China|Chiriqui Province...|Medium-Light|Elegantly fruit-t...|\n",
            "|Panama Mokkita Na...|https://www.coffe...|   Paradise Roasters|        Hilo, Hawaii|     Boquete, Panama|       Light|Richly floral, fr...|\n",
            "|   Mama Cata Mokkita|https://www.coffe...|          Cafe Unido|    Washington, D.C.|Boquete growing r...|Medium-Light|Rich, resonant, l...|\n",
            "|   Mama Cata Mokkita|https://www.coffe...|   Paradise Roasters|Minneapolis, Minn...|Boquete growing r...|Medium-Light|Aromatically othe...|\n",
            "|Ecuador COE 1st p...|https://www.coffe...|           GK Coffee|       Yilan, Taiwan|Saraguro, Loja, E...|       Light|Exceptionally bal...|\n",
            "|Ethiopia Tamiru T...|https://www.coffe...|  Genesis Coffee Lab|    Big Lake, Alaska|Sidamo (also Sida...|       Light|Richly sweet-tart...|\n",
            "|Ecuador Taza Dora...|https://www.coffe...|   Paradise Roasters|Minneapolis, Minn...|San Jose de Minas...|Medium-Light|Richly floral-ton...|\n",
            "|Ecuador Finca Cru...|https://www.coffe...|Simon Hsieh Aroma...|     Taoyuan, Taiwan|San Jose de Minas...| Medium-Dark|Decadently rich, ...|\n",
            "|Magic Cat Kenya C...|https://www.coffe...|Good Chance Biote...|Taichung City, Ta...|Murang'a County, ...|Medium-Light|Sweetly savory, r...|\n",
            "|Magic Cat Civet E...|https://www.coffe...|Good Chance Biote...|Taichung City, Ta...|Sidamo growing re...|Medium-Light| Sweetly tart, vi...|\n",
            "|  Kona Geisha Washed|https://www.coffe...|   Paradise Roasters|        Hilo, Hawaii|Holualoa, North K...|       Light|High-toned, tropi...|\n",
            "|Kona Mokka Champa...|https://www.coffe...|   Paradise Roasters|        Hilo, Hawaii|Kona growing regi...|       Light|Elegantly floral,...|\n",
            "|Colombia La Siria...|https://www.coffe...|Bird Rock Coffee ...|San Diego, Califo...|La Argentina, Hui...|Medium-Light|Delicately fruit-...|\n",
            "|Panama Boquete To...|https://www.coffe...|  Bona Kafo Roastery|   Kaohsiung, Taiwan|     Boquete, Panama|       Light|Sweetly floral an...|\n",
            "|Panama Hacienda L...|https://www.coffe...|      Euphora Coffee|      Taipei, Taiwan|Boquete growing r...|       Light|Intricate, delica...|\n",
            "|    Geisha Champagne|https://www.coffe...|   Heavenly Hawaiian|   Holualoa, Hawai’i|Holualoa, North K...|Medium-Light|Balanced, juicy, ...|\n",
            "|Kona Geisha Peabe...|https://www.coffe...|   Paradise Roasters|        Hilo, Hawaii|Holualoa, Hawai’i...|       Light|Elegantly bright,...|\n",
            "|Tanzania Acacia H...|https://www.coffe...|    Chromatic Coffee|San Jose, California|Ngorongoro, Tanza...|Medium-Light|Deep-toned, richl...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Drop the 'with_milk' column\n",
        "df_spark = df_spark.drop('with_milk')\n",
        "\n",
        "# Drop rows with missing values in the target columns\n",
        "df_spark = df_spark.dropna(subset=['aroma', 'acid', 'aftertaste'])\n",
        "\n",
        "# Drop unnecessary columns: 'desc_2', 'desc_3'\n",
        "df_spark = df_spark.drop('desc_2', 'desc_3')\n",
        "\n",
        "# Show remaining missing values\n",
        "df_spark.select([df_spark.columns[i] for i in range(len(df_spark.columns)) if df_spark.agg({df_spark.columns[i]: \"sum\"}).collect()[0][0] is None]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR3Vqf0WSSLf",
        "outputId": "d124c5d6-8b40-4f18-eb58-bfda2ab2369c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: string (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: string (nullable = true)\n",
            " |-- acid: string (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- flavor: string (nullable = true)\n",
            " |-- aftertaste: string (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n",
            "+---------+------+--------------------+--------------------+------------+\n",
            "|cost_12oz|rating|             roaster|              origin|       roast|\n",
            "+---------+------+--------------------+--------------------+------------+\n",
            "|  2721.55|    96|           GK Coffee|Nueva Suiza, Chir...|Medium-Light|\n",
            "|  1360.78|    90|           GK Coffee|  Paso Ancho, Panama|       Light|\n",
            "|  1360.78|    90|Plat Coffee Roastery|Chiriqui Province...|Medium-Light|\n",
            "|      750|    92|   Paradise Roasters|     Boquete, Panama|       Light|\n",
            "|      450|    90|          Cafe Unido|Boquete growing r...|Medium-Light|\n",
            "|      450|    94|   Paradise Roasters|Boquete growing r...|Medium-Light|\n",
            "|   435.45|    92|           GK Coffee|Saraguro, Loja, E...|       Light|\n",
            "|      435|    92|  Genesis Coffee Lab|Sidamo (also Sida...|       Light|\n",
            "|      420|    92|   Paradise Roasters|San Jose de Minas...|Medium-Light|\n",
            "|    391.9|    90|Simon Hsieh Aroma...|San Jose de Minas...| Medium-Dark|\n",
            "|      309|    88|Good Chance Biote...|Murang'a County, ...|Medium-Light|\n",
            "|      309|    86|Good Chance Biote...|Sidamo growing re...|Medium-Light|\n",
            "|      300|    92|   Paradise Roasters|Holualoa, North K...|       Light|\n",
            "|      300|    90|   Paradise Roasters|Kona growing regi...|       Light|\n",
            "|      285|    92|Bird Rock Coffee ...|La Argentina, Hui...|Medium-Light|\n",
            "|   272.16|    88|  Bona Kafo Roastery|     Boquete, Panama|       Light|\n",
            "|      270|    92|      Euphora Coffee|Boquete growing r...|       Light|\n",
            "|      246|    88|   Heavenly Hawaiian|Holualoa, North K...|Medium-Light|\n",
            "|      240|    90|   Paradise Roasters|Holualoa, Hawai’i...|       Light|\n",
            "|      240|    90|    Chromatic Coffee|Ngorongoro, Tanza...|Medium-Light|\n",
            "+---------+------+--------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------------+----------------+\n",
            "|(cost_12oz IS NULL)|(rating IS NULL)|\n",
            "+-------------------+----------------+\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "|              false|           false|\n",
            "+-------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check data types of the relevant columns\n",
        "df_spark.printSchema()\n",
        "\n",
        "# Check for null values in the relevant columns\n",
        "df_spark.select([col for col in ['cost_12oz', 'rating', 'roaster', 'origin', 'roast']]).show()\n",
        "\n",
        "# Verify that all relevant columns are numeric and have no nulls\n",
        "df_spark.select([col(\"cost_12oz\").isNull(), col(\"rating\").isNull()]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BPfbLpfS71B",
        "outputId": "610661ab-b8dd-4d97-f5bb-6618603dc587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: string (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: double (nullable = true)\n",
            " |-- acid: double (nullable = true)\n",
            " |-- body: double (nullable = true)\n",
            " |-- flavor: double (nullable = true)\n",
            " |-- aftertaste: double (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert relevant columns to double (numeric type)\n",
        "columns_to_convert = ['aroma', 'acid', 'body', 'flavor', 'aftertaste']\n",
        "\n",
        "for column in columns_to_convert:\n",
        "    df_spark = df_spark.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "# Verify that the conversion was successful\n",
        "df_spark.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VXbCYkWATQ7A"
      },
      "outputs": [],
      "source": [
        "# Check and drop rows with null values in the original columns\n",
        "# Assuming df_spark is your main DataFrame\n",
        "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
        "columns_to_check = ['cost_12oz', 'aroma', 'acid', 'body', 'flavor', 'aftertaste', 'roaster', 'origin', 'roast']\n",
        "train_data = train_data.na.drop(subset=columns_to_check)\n",
        "test_data = test_data.na.drop(subset=columns_to_check)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF-XFsQ0s-dJ",
        "outputId": "184a400e-999c-4542-d310-6b1a49677f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: double (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: double (nullable = true)\n",
            " |-- acid: double (nullable = true)\n",
            " |-- body: double (nullable = true)\n",
            " |-- flavor: double (nullable = true)\n",
            " |-- aftertaste: double (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'cost_12oz' to double\n",
        "train_data = train_data.withColumn(\"cost_12oz\", col(\"cost_12oz\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"cost_12oz\", col(\"cost_12oz\").cast(\"double\"))\n",
        "\n",
        "# Verify the schema to ensure the conversion\n",
        "train_data.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQoGktAxt672",
        "outputId": "44e9dd2d-53fb-4fd8-de8e-0f0a32068c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: double (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: double (nullable = true)\n",
            " |-- acid: double (nullable = true)\n",
            " |-- body: double (nullable = true)\n",
            " |-- flavor: double (nullable = true)\n",
            " |-- aftertaste: double (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: double (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: double (nullable = true)\n",
            " |-- acid: double (nullable = true)\n",
            " |-- body: double (nullable = true)\n",
            " |-- flavor: double (nullable = true)\n",
            " |-- aftertaste: double (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'rating' to double in both train and test data\n",
        "train_data = train_data.withColumn(\"rating\", col(\"rating\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"rating\", col(\"rating\").cast(\"double\"))\n",
        "\n",
        "# Verify the schema to ensure the conversion\n",
        "train_data.printSchema()\n",
        "test_data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6_g6HqguEAI",
        "outputId": "b3b2b5a7-9583-48b8-a97d-42702f0f5413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|rating|\n",
            "+------+\n",
            "+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check for non-numeric values in 'rating' column\n",
        "train_data.filter(col(\"rating\").cast(\"double\").isNull()).select(\"rating\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qn4Ylghx_4BS"
      },
      "outputs": [],
      "source": [
        "# Modify StringIndexer to handle unseen labels\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"skip\").fit(train_data) for column in ['roaster', 'origin', 'roast']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mcoPlQKQuewM"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "# defining the stages for the pipeline\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(train_data) for column in ['roaster', 'origin', 'roast']]\n",
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_vec\") for column in ['roaster', 'origin', 'roast']]\n",
        "\n",
        "# Assembling the features\n",
        "assembler = VectorAssembler(inputCols=['cost_12oz', 'aroma', 'acid', 'body', 'flavor', 'aftertaste'] + [col+\"_vec\" for col in ['roaster', 'origin', 'roast']], outputCol=\"features\")\n",
        "\n",
        "# Define the RandomForestRegressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline_simple = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
        "\n",
        "# Now you can fit the model\n",
        "model_simple = pipeline_simple.fit(train_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OngmHRIAnJo",
        "outputId": "e4c5bfb2-f828-451d-fe61-bb1b18b442b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of simplified model: 0.5133443318676517\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Convert 'rating' to double in both train and test data\n",
        "train_data = train_data.withColumn(\"rating\", col(\"rating\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"rating\", col(\"rating\").cast(\"double\"))\n",
        "\n",
        "# Ensure that 'cost_12oz' is also of type double\n",
        "train_data = train_data.withColumn(\"cost_12oz\", col(\"cost_12oz\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"cost_12oz\", col(\"cost_12oz\").cast(\"double\"))\n",
        "\n",
        "# Modify StringIndexer to handle unseen labels\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"skip\").fit(train_data) for column in ['roaster', 'origin', 'roast']]\n",
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_vec\") for column in ['roaster', 'origin', 'roast']]\n",
        "assembler = VectorAssembler(inputCols=['cost_12oz', 'aroma', 'acid', 'body', 'flavor', 'aftertaste'] + [col+\"_vec\" for col in ['roaster', 'origin', 'roast']], outputCol=\"features\")\n",
        "\n",
        "# Define the RandomForestRegressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline_simple = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
        "\n",
        "# Fit the simplified model\n",
        "model_simple = pipeline_simple.fit(train_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions_simple = model_simple.transform(test_data)\n",
        "\n",
        "# Define the evaluator for regression\n",
        "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Evaluate the simplified model\n",
        "rmse_simple = evaluator.evaluate(predictions_simple)\n",
        "\n",
        "print(f\"RMSE of simplified model: {rmse_simple}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiJ0sUTfuObu",
        "outputId": "d07a1fe5-43f5-49ce-d3e8-03b358daa739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of simplified model: 0.5133443318676517\n"
          ]
        }
      ],
      "source": [
        "# Fit the simplified model\n",
        "model_simple = pipeline_simple.fit(train_data)\n",
        "\n",
        "# Check if the simplified pipeline works\n",
        "predictions_simple = model_simple.transform(test_data)\n",
        "\n",
        "# Evaluate the simplified model\n",
        "rmse_simple = evaluator.evaluate(predictions_simple)\n",
        "\n",
        "print(f\"RMSE of simplified model: {rmse_simple}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0gCnmu1UR4S",
        "outputId": "283cb437-1de7-4b58-bc2c-9a7e51d11fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+--------+-----------------+\n",
            "|                name|                slug|rating|             roaster|            location|              origin|       roast|cost_12oz|review_date|aroma|acid|body|flavor|aftertaste|              desc_1|Location_Latitude|Location_Longitude|Origin_Latitude|Origin_Longitude|Blend/Single Origin|      desc_1_cleaned|features|       prediction|\n",
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+--------+-----------------+\n",
            "|         #She_Builds|https://www.coffe...|  84.0|         Dávila Kafe|    Washington, D.C.|     Haiti; Ethiopia|Medium-Light|     18.0|     21-Mar| 18.0|16.0|16.0|  18.0|      16.0|Fruit-toned, choc...|       38.8950368|       -77.0365427|           11.2|           35.35|              Blend|fruittoned bluebe...|  [18.0]|85.71871322257496|\n",
            "|100% Kona Bourbon...|https://www.coffe...|  90.0|Hula Daddy Kona C...|    Holualoa, Hawaii|Holualoa, North K...|Medium-Light|    94.43|     21-Nov| 18.0|18.0|18.0|  18.0|      18.0|Richly aromatic, ...|      19.62947805|      -155.9168803|       41.77562|     -109.655664|      Single Origin|aromatic blackber...| [94.43]|89.89175416133513|\n",
            "|2020 Savage Aucti...|https://www.coffe...|  88.0|       Kakalove Cafe|     Chia-Yi, Taiwan|Chiriqui, Boquete...|Medium-Light|     72.0|     20-Oct| 18.0|18.0|18.0|  18.0|      16.0|Harmoniously swee...|       23.4818972|        120.462318|       8.716062|      -82.440641|      Single Origin|harmoniously swee...|  [72.0]| 87.5066945083263|\n",
            "|         5a Poniente|https://www.coffe...|  76.0|        El Gran Cafe|  Antigua, Guatemala|  Antigua, Guatemala|      Medium|      6.0|     21-Dec| 16.0|14.0|16.0|  16.0|      14.0|Richly bitterswee...|       10.3113166|       -85.7715578|     10.3113166|     -85.7715578|      Single Origin|bittersweet hop f...|   [6.0]|80.83593028008265|\n",
            "|         5a Poniente|https://www.coffe...|  82.0|        El Gran Cafe|  Antigua, Guatemala|Antigua growing r...|Medium-Light|      6.0|     22-Nov| 16.0|16.0|16.0|  18.0|      16.0|Sweetly herb- and...|             NULL|              NULL|           NULL|            NULL|               NULL|                NULL|   [6.0]|80.83593028008265|\n",
            "|         5a Poniente|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...| Medium-Dark|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Chocolaty, sweetl...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|smoky scorched me...|   [5.0]|80.83593028008265|\n",
            "|              5a Sur|https://www.coffe...|  78.0|        El Gran Cafe|  Antigua, Guatemala|  Antigua, Guatemala|      Medium|      6.0|     21-Dec| 16.0|14.0|16.0|  18.0|      14.0|Crisply sweet, nu...|       10.3113166|       -85.7715578|     10.3113166|     -85.7715578|      Single Origin|nuttoned cashew b...|   [6.0]|80.83593028008265|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [5.0]|80.83593028008265|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [5.0]|80.83593028008265|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      6.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [6.0]|80.83593028008265|\n",
            "|Acatenango Pacama...|https://www.coffe...|  84.0|       Qin Mi Coffee|Taoyuan City, Taiwan|Acatenango Valley...|Medium-Light|    31.17|     21-Sep| 16.0|16.0|18.0|  18.0|      16.0|Cleanly fruit-for...|       24.9929995|       121.3010003|       14.55194|       -90.94222|      Single Origin|cleanly fruitforw...| [31.17]| 87.2180289009645|\n",
            "|      Aces La Juntas|https://www.coffe...|  86.0| JBC Coffee Roasters|  Madison, Wisconsin|Chinas, San Agust...|       Light|    27.97|     21-Feb| 18.0|18.0|16.0|  18.0|      16.0|Berry- and chocol...|        43.074761|       -89.3837613|       1.882076|     -76.2728979|      Single Origin|berry chocolateto...| [27.97]|87.47119225009742|\n",
            "|Aged Sumatra Ulos...|https://www.coffe...|  88.0|   Paradise Roasters|Minneapolis, Minn...|Lintong growing r...|      Medium|    18.95|     21-Mar| 18.0|16.0|18.0|  18.0|      18.0|A splendid, uncom...|       44.9772995|       -93.2654692|         2.6055|         98.6996|      Single Origin|splendid uncompro...| [18.95]| 86.5581534753831|\n",
            "|            Angamaza|https://www.coffe...|  88.0| JBC Coffee Roasters|  Madison, Wisconsin|Conganama, Loja P...|Medium-Light|     20.0|     21-Feb| 18.0|18.0|18.0|  18.0|      16.0|Bright, delicatel...|        43.074761|       -89.3837613|       -3.99313|       -79.20422|      Single Origin|delicately fruitt...|  [20.0]|85.75737874142929|\n",
            "|   Asobombo Colombia|https://www.coffe...|  86.0| JBC Coffee Roasters|  Madison, Wisconsin|Pitalito, Huila D...|Medium-Light|     20.0|     23-May| 18.0|18.0|16.0|  18.0|      16.0|Balanced, crisply...|        43.074761|       -89.3837613|      1.8447122|     -76.0456886|      Single Origin|pistachio date wi...|  [20.0]|85.75737874142929|\n",
            "|Banko Gotiti Ethi...|https://www.coffe...|  90.0| JBC Coffee Roasters|  Madison, Wisconsin|Gedeb District, G...|Medium-Light|     20.0|     23-May| 18.0|18.0|16.0|  20.0|      18.0|Richly aromatic, ...|        43.074761|       -89.3837613|      13.249606|       39.520505|      Single Origin|aromatic deeptone...|  [20.0]|85.75737874142929|\n",
            "|Birhanu Sisters’ ...|https://www.coffe...|  86.0|      Swelter Coffee|El Cerrito, Calif...|Yirgacheffe growi...|Medium-Light|     18.0|     22-Oct| 18.0|18.0|16.0|  18.0|      16.0| Cocoa-toned, jui...|       37.9154056|       -122.301411|         6.1629|         38.2281|      Single Origin|cocoatoned vibran...|  [18.0]|85.71871322257496|\n",
            "|Bourbon Pointu Na...|https://www.coffe...|  88.0|    Kona Farm Direct|   Holualoa, Hawai’i|Kona growing regi...|Medium-Light|    85.71|     21-Apr| 18.0|18.0|18.0|  18.0|      16.0|Delicately sweet,...|      19.62947805|      -155.9168803|      30.829423|      -82.609586|      Single Origin|delicately fruitt...| [85.71]|88.83110890817585|\n",
            "|          Brazil COE|https://www.coffe...|  84.0|         Le Brewlife|    Taichung, Taiwan|Vale da Grama, Mi...|Medium-Light|    24.82|     21-Sep| 18.0|16.0|16.0|  18.0|      16.0|Gently fruit-tone...|        24.163162|       120.6478282|      -20.41584|        -44.0647|      Single Origin|fruittoned earthy...| [24.82]|86.94978721128417|\n",
            "|Brazil Daterra Ar...|https://www.coffe...|  86.0|   Paradise Roasters|Minneapolis, Minn...|Cerrado growing r...|       Light|   119.85|     21-Mar| 18.0|16.0|18.0|  18.0|      16.0|Very fruit-forwar...|       44.9772995|       -93.2654692|       -23.5523|        -47.8344|      Single Origin|fruitforward mulb...|[119.85]|89.80501743424294|\n",
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+--------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Simplified pipeline\n",
        "assembler = VectorAssembler(inputCols=['cost_12oz'], outputCol=\"features\")\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\", numTrees=10, maxDepth=5)\n",
        "\n",
        "# Simple pipeline with only one feature\n",
        "pipeline_simple = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Fit the simplified model\n",
        "model_simple = pipeline_simple.fit(train_data)\n",
        "\n",
        "# Check if the simplified pipeline works\n",
        "predictions_simple = model_simple.transform(test_data)\n",
        "predictions_simple.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vna6vbEUUYUS",
        "outputId": "54abac2e-fabb-4291-fbdc-9b21107559df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+------------------+-----------------+\n",
            "|                name|                slug|rating|             roaster|            location|              origin|       roast|cost_12oz|review_date|aroma|acid|body|flavor|aftertaste|              desc_1|Location_Latitude|Location_Longitude|Origin_Latitude|Origin_Longitude|Blend/Single Origin|      desc_1_cleaned|          features|       prediction|\n",
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+------------------+-----------------+\n",
            "|         #She_Builds|https://www.coffe...|  84.0|         Dávila Kafe|    Washington, D.C.|     Haiti; Ethiopia|Medium-Light|     18.0|     21-Mar| 18.0|16.0|16.0|  18.0|      16.0|Fruit-toned, choc...|       38.8950368|       -77.0365427|           11.2|           35.35|              Blend|fruittoned bluebe...|  [18.0,18.0,16.0]|85.31380132594062|\n",
            "|100% Kona Bourbon...|https://www.coffe...|  90.0|Hula Daddy Kona C...|    Holualoa, Hawaii|Holualoa, North K...|Medium-Light|    94.43|     21-Nov| 18.0|18.0|18.0|  18.0|      18.0|Richly aromatic, ...|      19.62947805|      -155.9168803|       41.77562|     -109.655664|      Single Origin|aromatic blackber...| [94.43,18.0,18.0]|89.30323467692025|\n",
            "|2020 Savage Aucti...|https://www.coffe...|  88.0|       Kakalove Cafe|     Chia-Yi, Taiwan|Chiriqui, Boquete...|Medium-Light|     72.0|     20-Oct| 18.0|18.0|18.0|  18.0|      16.0|Harmoniously swee...|       23.4818972|        120.462318|       8.716062|      -82.440641|      Single Origin|harmoniously swee...|  [72.0,18.0,18.0]|88.61105687669603|\n",
            "|         5a Poniente|https://www.coffe...|  76.0|        El Gran Cafe|  Antigua, Guatemala|  Antigua, Guatemala|      Medium|      6.0|     21-Dec| 16.0|14.0|16.0|  16.0|      14.0|Richly bitterswee...|       10.3113166|       -85.7715578|     10.3113166|     -85.7715578|      Single Origin|bittersweet hop f...|   [6.0,16.0,14.0]|77.16697097779718|\n",
            "|         5a Poniente|https://www.coffe...|  82.0|        El Gran Cafe|  Antigua, Guatemala|Antigua growing r...|Medium-Light|      6.0|     22-Nov| 16.0|16.0|16.0|  18.0|      16.0|Sweetly herb- and...|             NULL|              NULL|           NULL|            NULL|               NULL|                NULL|   [6.0,16.0,16.0]|80.95194650996852|\n",
            "|         5a Poniente|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...| Medium-Dark|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Chocolaty, sweetl...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|smoky scorched me...|   [5.0,14.0,14.0]|71.26347079820763|\n",
            "|              5a Sur|https://www.coffe...|  78.0|        El Gran Cafe|  Antigua, Guatemala|  Antigua, Guatemala|      Medium|      6.0|     21-Dec| 16.0|14.0|16.0|  18.0|      14.0|Crisply sweet, nu...|       10.3113166|       -85.7715578|     10.3113166|     -85.7715578|      Single Origin|nuttoned cashew b...|   [6.0,16.0,14.0]|77.16697097779718|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [5.0,14.0,14.0]|71.26347079820763|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      5.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [5.0,14.0,14.0]|71.26347079820763|\n",
            "|              5a Sur|https://www.coffe...|  72.0|        El Gran Café|  Antigua, Guatemala|Antigua growing r...|      Medium|      6.0|     20-Oct| 14.0|14.0|14.0|  16.0|      14.0|Sweetly nut- and ...|       10.3113166|       -85.7715578|       14.56111|       -90.73444|      Single Origin|nut cocoatoned po...|   [6.0,14.0,14.0]|71.26347079820763|\n",
            "|Acatenango Pacama...|https://www.coffe...|  84.0|       Qin Mi Coffee|Taoyuan City, Taiwan|Acatenango Valley...|Medium-Light|    31.17|     21-Sep| 16.0|16.0|18.0|  18.0|      16.0|Cleanly fruit-for...|       24.9929995|       121.3010003|       14.55194|       -90.94222|      Single Origin|cleanly fruitforw...| [31.17,16.0,16.0]|82.95324620791769|\n",
            "|      Aces La Juntas|https://www.coffe...|  86.0| JBC Coffee Roasters|  Madison, Wisconsin|Chinas, San Agust...|       Light|    27.97|     21-Feb| 18.0|18.0|16.0|  18.0|      16.0|Berry- and chocol...|        43.074761|       -89.3837613|       1.882076|     -76.2728979|      Single Origin|berry chocolateto...| [27.97,18.0,18.0]|88.22490277610588|\n",
            "|Aged Sumatra Ulos...|https://www.coffe...|  88.0|   Paradise Roasters|Minneapolis, Minn...|Lintong growing r...|      Medium|    18.95|     21-Mar| 18.0|16.0|18.0|  18.0|      18.0|A splendid, uncom...|       44.9772995|       -93.2654692|         2.6055|         98.6996|      Single Origin|splendid uncompro...| [18.95,18.0,16.0]|85.09428913081867|\n",
            "|            Angamaza|https://www.coffe...|  88.0| JBC Coffee Roasters|  Madison, Wisconsin|Conganama, Loja P...|Medium-Light|     20.0|     21-Feb| 18.0|18.0|18.0|  18.0|      16.0|Bright, delicatel...|        43.074761|       -89.3837613|       -3.99313|       -79.20422|      Single Origin|delicately fruitt...|  [20.0,18.0,18.0]|88.02456864387577|\n",
            "|   Asobombo Colombia|https://www.coffe...|  86.0| JBC Coffee Roasters|  Madison, Wisconsin|Pitalito, Huila D...|Medium-Light|     20.0|     23-May| 18.0|18.0|16.0|  18.0|      16.0|Balanced, crisply...|        43.074761|       -89.3837613|      1.8447122|     -76.0456886|      Single Origin|pistachio date wi...|  [20.0,18.0,18.0]|88.02456864387577|\n",
            "|Banko Gotiti Ethi...|https://www.coffe...|  90.0| JBC Coffee Roasters|  Madison, Wisconsin|Gedeb District, G...|Medium-Light|     20.0|     23-May| 18.0|18.0|16.0|  20.0|      18.0|Richly aromatic, ...|        43.074761|       -89.3837613|      13.249606|       39.520505|      Single Origin|aromatic deeptone...|  [20.0,18.0,18.0]|88.02456864387577|\n",
            "|Birhanu Sisters’ ...|https://www.coffe...|  86.0|      Swelter Coffee|El Cerrito, Calif...|Yirgacheffe growi...|Medium-Light|     18.0|     22-Oct| 18.0|18.0|16.0|  18.0|      16.0| Cocoa-toned, jui...|       37.9154056|       -122.301411|         6.1629|         38.2281|      Single Origin|cocoatoned vibran...|  [18.0,18.0,18.0]|87.85554425363186|\n",
            "|Bourbon Pointu Na...|https://www.coffe...|  88.0|    Kona Farm Direct|   Holualoa, Hawai’i|Kona growing regi...|Medium-Light|    85.71|     21-Apr| 18.0|18.0|18.0|  18.0|      16.0|Delicately sweet,...|      19.62947805|      -155.9168803|      30.829423|      -82.609586|      Single Origin|delicately fruitt...| [85.71,18.0,18.0]|88.80100234101741|\n",
            "|          Brazil COE|https://www.coffe...|  84.0|         Le Brewlife|    Taichung, Taiwan|Vale da Grama, Mi...|Medium-Light|    24.82|     21-Sep| 18.0|16.0|16.0|  18.0|      16.0|Gently fruit-tone...|        24.163162|       120.6478282|      -20.41584|        -44.0647|      Single Origin|fruittoned earthy...| [24.82,18.0,16.0]|85.09494881652465|\n",
            "|Brazil Daterra Ar...|https://www.coffe...|  86.0|   Paradise Roasters|Minneapolis, Minn...|Cerrado growing r...|       Light|   119.85|     21-Mar| 18.0|16.0|18.0|  18.0|      16.0|Very fruit-forwar...|       44.9772995|       -93.2654692|       -23.5523|        -47.8344|      Single Origin|fruitforward mulb...|[119.85,18.0,16.0]|85.18994881652465|\n",
            "+--------------------+--------------------+------+--------------------+--------------------+--------------------+------------+---------+-----------+-----+----+----+------+----------+--------------------+-----------------+------------------+---------------+----------------+-------------------+--------------------+------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add more features\n",
        "assembler = VectorAssembler(inputCols=['cost_12oz', 'aroma', 'acid'], outputCol=\"features\")\n",
        "\n",
        "# Update the pipeline\n",
        "pipeline_simple = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Fit the model\n",
        "model_simple = pipeline_simple.fit(train_data)\n",
        "\n",
        "# Check predictions\n",
        "predictions_simple = model_simple.transform(test_data)\n",
        "predictions_simple.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NAug18SgUdT_"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=['cost_12oz', 'aroma', 'acid', 'body', 'flavor', 'aftertaste'], outputCol=\"features\", handleInvalid='skip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW0bgdvQTEgV",
        "outputId": "119f58d8-d699-4aab-bc16-1ebc1985abd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "|cost_12oz|aroma|acid|body|flavor|aftertaste|             roaster|              origin|       roast|\n",
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "|    47.04| 18.0|16.0|18.0|  18.0|      16.0|Pacific Coffee Re...|Ka‘ū growing regi...|       Light|\n",
            "|     43.5| 18.0|16.0|16.0|  18.0|      16.0|   Kona Hills Coffee|Kona growing dist...|Medium-Light|\n",
            "|    47.91| 18.0|18.0|18.0|  18.0|      16.0|    Kona Farm Direct|Kona growing regi...|Medium-Light|\n",
            "|     19.5| 16.0|16.0|18.0|  18.0|      14.0|Colibrije Special...|Chiapas State, Me...|      Medium|\n",
            "|    15.38| 16.0|16.0|16.0|  16.0|      16.0|    Coffee by Design|            Ethiopia|Medium-Light|\n",
            "|     4.81| 18.0|16.0|16.0|  18.0|      16.0|     Mr. Chao Coffee|               Kenya|Medium-Light|\n",
            "|    13.99| 18.0|16.0|16.0|  18.0|      16.0|        Coffee Hound| Costa Rica; Sumatra|Medium-Light|\n",
            "|      5.0| 16.0|14.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|      Medium|\n",
            "|      5.0| 16.0|14.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|      Medium|\n",
            "|      5.0| 16.0|14.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|      Medium|\n",
            "|      5.0| 16.0|16.0|16.0|  18.0|      16.0|        El Gran Cafe|Antigua growing r...|Medium-Light|\n",
            "|      5.0| 16.0|16.0|16.0|  18.0|      16.0|        El Gran Cafe|Antigua growing r...|Medium-Light|\n",
            "|      5.0| 16.0|16.0|16.0|  18.0|      16.0|        El Gran Cafe|Antigua growing r...|Medium-Light|\n",
            "|      5.0| 16.0|16.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|Medium-Light|\n",
            "|      5.0| 16.0|16.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|Medium-Light|\n",
            "|      5.0| 16.0|16.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|Medium-Light|\n",
            "|      6.0| 16.0|16.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|Medium-Light|\n",
            "|      5.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...| Medium-Dark|\n",
            "|      5.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...| Medium-Dark|\n",
            "|      6.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...| Medium-Dark|\n",
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "|cost_12oz|aroma|acid|body|flavor|aftertaste|             roaster|              origin|       roast|\n",
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "|     18.0| 18.0|16.0|16.0|  18.0|      16.0|         Dávila Kafe|     Haiti; Ethiopia|Medium-Light|\n",
            "|    94.43| 18.0|18.0|18.0|  18.0|      18.0|Hula Daddy Kona C...|Holualoa, North K...|Medium-Light|\n",
            "|     72.0| 18.0|18.0|18.0|  18.0|      16.0|       Kakalove Cafe|Chiriqui, Boquete...|Medium-Light|\n",
            "|      6.0| 16.0|14.0|16.0|  16.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|      Medium|\n",
            "|      6.0| 16.0|16.0|16.0|  18.0|      16.0|        El Gran Cafe|Antigua growing r...|Medium-Light|\n",
            "|      5.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...| Medium-Dark|\n",
            "|      6.0| 16.0|14.0|16.0|  18.0|      14.0|        El Gran Cafe|  Antigua, Guatemala|      Medium|\n",
            "|      5.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...|      Medium|\n",
            "|      5.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...|      Medium|\n",
            "|      6.0| 14.0|14.0|14.0|  16.0|      14.0|        El Gran Café|Antigua growing r...|      Medium|\n",
            "|    31.17| 16.0|16.0|18.0|  18.0|      16.0|       Qin Mi Coffee|Acatenango Valley...|Medium-Light|\n",
            "|    27.97| 18.0|18.0|16.0|  18.0|      16.0| JBC Coffee Roasters|Chinas, San Agust...|       Light|\n",
            "|    18.95| 18.0|16.0|18.0|  18.0|      18.0|   Paradise Roasters|Lintong growing r...|      Medium|\n",
            "|     20.0| 18.0|18.0|18.0|  18.0|      16.0| JBC Coffee Roasters|Conganama, Loja P...|Medium-Light|\n",
            "|     20.0| 18.0|18.0|16.0|  18.0|      16.0| JBC Coffee Roasters|Pitalito, Huila D...|Medium-Light|\n",
            "|     20.0| 18.0|18.0|16.0|  20.0|      18.0| JBC Coffee Roasters|Gedeb District, G...|Medium-Light|\n",
            "|     18.0| 18.0|18.0|16.0|  18.0|      16.0|      Swelter Coffee|Yirgacheffe growi...|Medium-Light|\n",
            "|    85.71| 18.0|18.0|18.0|  18.0|      16.0|    Kona Farm Direct|Kona growing regi...|Medium-Light|\n",
            "|    24.82| 18.0|16.0|16.0|  18.0|      16.0|         Le Brewlife|Vale da Grama, Mi...|Medium-Light|\n",
            "|   119.85| 18.0|16.0|18.0|  18.0|      16.0|   Paradise Roasters|Cerrado growing r...|       Light|\n",
            "+---------+-----+----+----+------+----------+--------------------+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# List of columns to check for nulls and remove them\n",
        "columns_to_check = [\n",
        "    'cost_12oz',\n",
        "    'aroma',\n",
        "    'acid',\n",
        "    'body',\n",
        "    'flavor',\n",
        "    'aftertaste',\n",
        "    'roaster',\n",
        "    'origin',\n",
        "    'roast'\n",
        "]\n",
        "\n",
        "# Drop rows with null values in any of these columns\n",
        "train_data = train_data.na.drop(subset=columns_to_check)\n",
        "test_data = test_data.na.drop(subset=columns_to_check)\n",
        "\n",
        "# Verify that no null values remain in these columns\n",
        "train_data.select([col for col in columns_to_check]).show()\n",
        "test_data.select([col for col in columns_to_check]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ71kkx1V5Rk",
        "outputId": "768d4ae5-bbc0-4b49-cde7-291a23ff57ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- slug: string (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- roaster: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- roast: string (nullable = true)\n",
            " |-- cost_12oz: double (nullable = true)\n",
            " |-- review_date: string (nullable = true)\n",
            " |-- aroma: double (nullable = true)\n",
            " |-- acid: double (nullable = true)\n",
            " |-- body: double (nullable = true)\n",
            " |-- flavor: double (nullable = true)\n",
            " |-- aftertaste: double (nullable = true)\n",
            " |-- desc_1: string (nullable = true)\n",
            " |-- Location_Latitude: string (nullable = true)\n",
            " |-- Location_Longitude: string (nullable = true)\n",
            " |-- Origin_Latitude: string (nullable = true)\n",
            " |-- Origin_Longitude: string (nullable = true)\n",
            " |-- Blend/Single Origin: string (nullable = true)\n",
            " |-- desc_1_cleaned: string (nullable = true)\n",
            "\n",
            "Null values in cost_12oz: 0\n",
            "Null values in aroma: 0\n",
            "Null values in acid: 0\n",
            "Null values in body: 0\n",
            "Null values in flavor: 0\n",
            "Null values in aftertaste: 0\n",
            "Null values in roaster: 0\n",
            "Null values in origin: 0\n",
            "Null values in roast: 0\n"
          ]
        }
      ],
      "source": [
        "# Check the schema of the DataFrame to confirm data types\n",
        "train_data.printSchema()\n",
        "\n",
        "# Check for null values in each column\n",
        "for column in columns_to_check:\n",
        "    null_count = train_data.filter(train_data[column].isNull()).count()\n",
        "    print(f\"Null values in {column}: {null_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsf531g1WQzl",
        "outputId": "2abd3607-eb88-449d-b5e3-e8c6bd85819b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null values in cost_12oz after cleaning: 0\n",
            "Null values in aroma after cleaning: 0\n",
            "Null values in flavor after cleaning: 0\n",
            "Null values in aftertaste after cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with null values in the relevant columns\n",
        "columns_to_check = [\n",
        "    'cost_12oz',\n",
        "    'aroma',\n",
        "    'flavor',\n",
        "    'aftertaste'\n",
        "]\n",
        "\n",
        "# Drop rows with nulls in these columns\n",
        "train_data_clean = train_data.na.drop(subset=columns_to_check)\n",
        "test_data_clean = test_data.na.drop(subset=columns_to_check)\n",
        "\n",
        "# Verify no null values remain\n",
        "for column in columns_to_check:\n",
        "    null_count = train_data_clean.filter(train_data_clean[column].isNull()).count()\n",
        "    print(f\"Null values in {column} after cleaning: {null_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjYd6jXkWZuq",
        "outputId": "82501fc0-01e4-4782-8725-26f9ed6b3e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE on test data: 0.24428841078670538\n",
            "Best Model Params: {Param(parent='RandomForestRegressor_378c601dd7d0', name='bootstrap', doc='Whether bootstrap samples are used when building trees.'): True, Param(parent='RandomForestRegressor_378c601dd7d0', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='RandomForestRegressor_378c601dd7d0', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='RandomForestRegressor_378c601dd7d0', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestRegressor_378c601dd7d0', name='featuresCol', doc='features column name.'): 'features', Param(parent='RandomForestRegressor_378c601dd7d0', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent='RandomForestRegressor_378c601dd7d0', name='labelCol', doc='label column name.'): 'rating', Param(parent='RandomForestRegressor_378c601dd7d0', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='RandomForestRegressor_378c601dd7d0', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestRegressor_378c601dd7d0', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 15, Param(parent='RandomForestRegressor_378c601dd7d0', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='RandomForestRegressor_378c601dd7d0', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestRegressor_378c601dd7d0', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestRegressor_378c601dd7d0', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='RandomForestRegressor_378c601dd7d0', name='numTrees', doc='Number of trees to train (>= 1).'): 150, Param(parent='RandomForestRegressor_378c601dd7d0', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='RandomForestRegressor_378c601dd7d0', name='seed', doc='random seed.'): -7780055545539096562, Param(parent='RandomForestRegressor_378c601dd7d0', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Step 1: Encoding Categorical Variables with handleInvalid='skip'\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid='skip').fit(train_data_clean) for column in ['roaster', 'origin', 'roast']]\n",
        "\n",
        "# One-Hot Encoding the indexed columns\n",
        "encoders = [OneHotEncoder(inputCol=column+\"_index\", outputCol=column+\"_vec\") for column in ['roaster', 'origin', 'roast']]\n",
        "\n",
        "# Step 2: Assembling the Features\n",
        "assembler = VectorAssembler(inputCols=['cost_12oz', 'aroma', 'acid', 'body', 'flavor', 'aftertaste', 'roaster_vec', 'origin_vec', 'roast_vec'], outputCol=\"features\")\n",
        "\n",
        "# Step 3: Define the RandomForestRegressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
        "\n",
        "# Creating a Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
        "\n",
        "# Initialize a list to store the results\n",
        "results = []\n",
        "\n",
        "# Step 4: Define the parameter grid\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [50, 100, 150])\n",
        "             .addGrid(rf.maxDepth, [5, 10, 15])\n",
        "             .addGrid(rf.maxBins, [32, 64])\n",
        "             .addGrid(rf.minInstancesPerNode, [1, 2])\n",
        "             .build())\n",
        "\n",
        "# Step 5: Define the cross-validator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
        "                          numFolds=3)  # Use 3 folds for cross-validation\n",
        "\n",
        "# Step 6: Run cross-validation to tune hyperparameters\n",
        "cvModel = crossval.fit(train_data_clean)\n",
        "\n",
        "# Step 7: Extract hyperparameters and RMSE for each model\n",
        "for params, metric in zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics):\n",
        "    result = {\n",
        "        \"numTrees\": params[rf.numTrees],\n",
        "        \"maxDepth\": params[rf.maxDepth],\n",
        "        \"maxBins\": params[rf.maxBins],\n",
        "        \"minInstancesPerNode\": params[rf.minInstancesPerNode],\n",
        "        \"RMSE\": metric\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "# Step 8: Save the results to a CSV file\n",
        "csv_file = 'model_tuning_results.csv'\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=[\"numTrees\", \"maxDepth\", \"maxBins\", \"minInstancesPerNode\", \"RMSE\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(results)\n",
        "\n",
        "# Step 9: Evaluate the best model\n",
        "bestModel = cvModel.bestModel\n",
        "predictions = bestModel.transform(test_data_clean)\n",
        "rmse = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(predictions)\n",
        "\n",
        "print(f\"Best RMSE on test data: {rmse}\")\n",
        "print(f\"Best Model Params: {bestModel.stages[-1].extractParamMap()}\")  # Extract best model parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aGm3Rs40bRy9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create interaction features\n",
        "train_data_clean = train_data_clean.withColumn('aroma_acid', col('aroma') * col('acid'))\n",
        "train_data_clean = train_data_clean.withColumn('aroma_body', col('aroma') * col('body'))\n",
        "train_data_clean = train_data_clean.withColumn('acid_body', col('acid') * col('body'))\n",
        "\n",
        "test_data_clean = test_data_clean.withColumn('aroma_acid', col('aroma') * col('acid'))\n",
        "test_data_clean = test_data_clean.withColumn('aroma_body', col('aroma') * col('body'))\n",
        "test_data_clean = test_data_clean.withColumn('acid_body', col('acid') * col('body'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RyE_HADsb3Br"
      },
      "outputs": [],
      "source": [
        "# Update the assembler to include the new interaction features\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "    'cost_12oz',\n",
        "    'aroma',\n",
        "    'acid',\n",
        "    'body',\n",
        "    'flavor',\n",
        "    'aftertaste',\n",
        "    'roaster_vec',\n",
        "    'origin_vec',\n",
        "    'roast_vec',\n",
        "    'aroma_acid',\n",
        "    'aroma_body',\n",
        "    'acid_body'\n",
        "], outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIqwRMDOb7tO",
        "outputId": "d59f9277-5fd6-4db7-951c-6fd0a0739cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data after adding interaction features: 0.37963322628434437\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Define the RandomForestRegressor with the new feature set\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
        "\n",
        "# Creating a Pipeline that includes the new feature assembler\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
        "\n",
        "# Fit the model using the training data\n",
        "model = pipeline.fit(train_data_clean)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data_clean)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE) on test data after adding interaction features: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SsDVTKfb-Ew",
        "outputId": "87a64e25-8e4d-4262-dfb1-1a3d14626cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results have been saved to model_tuning_results_with_interactions.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Initialize a list to store the results\n",
        "results = []\n",
        "\n",
        "# Document the results\n",
        "results.append({\n",
        "    \"Interaction_Features_Used\": \"Yes\",\n",
        "    \"numTrees\": rf.getOrDefault(\"numTrees\"),\n",
        "    \"maxDepth\": rf.getOrDefault(\"maxDepth\"),\n",
        "    \"maxBins\": rf.getOrDefault(\"maxBins\"),\n",
        "    \"minInstancesPerNode\": rf.getOrDefault(\"minInstancesPerNode\"),\n",
        "    \"RMSE\": rmse\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "csv_file = 'model_tuning_results_with_interactions.csv'\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=[\"Interaction_Features_Used\", \"numTrees\", \"maxDepth\", \"maxBins\", \"minInstancesPerNode\", \"RMSE\"])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(f\"Results have been saved to {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "IdNdwvm3cbiW"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import PolynomialExpansion\n",
        "\n",
        "# Create polynomial features for numerical columns\n",
        "poly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=2)\n",
        "\n",
        "# Update the assembler to use polynomial features instead of the original features\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "    'log_cost_12oz',\n",
        "    'aroma',\n",
        "    'acid',\n",
        "    'body',\n",
        "    'flavor',\n",
        "    'aftertaste',\n",
        "    'roaster_vec',\n",
        "    'origin_vec',\n",
        "    'roast_vec',\n",
        "    'aroma_acid',\n",
        "    'aroma_body',\n",
        "    'acid_body'\n",
        "], outputCol=\"features\")\n",
        "\n",
        "# Create a pipeline including polynomial expansion\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, poly_expansion, rf])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yfjOECIZcghR"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler(inputCol=\"poly_features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Update the pipeline to include scaling\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, poly_expansion, scaler, rf])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjW3iSRhcuK_",
        "outputId": "bccc2407-0abf-48e9-d41d-2a9b0a851e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|     log_cost_12oz|\n",
            "+------------------+\n",
            "|3.8720339972117825|\n",
            "|3.7954891891721947|\n",
            "|3.8899818745512658|\n",
            "|3.0204248861443626|\n",
            "|2.7960610784249234|\n",
            "+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import log\n",
        "\n",
        "# Apply log transformation to 'cost_12oz' and create 'log_cost_12oz'\n",
        "train_data_clean = train_data_clean.withColumn('log_cost_12oz', log(col('cost_12oz') + 1))\n",
        "test_data_clean = test_data_clean.withColumn('log_cost_12oz', log(col('cost_12oz') + 1))\n",
        "\n",
        "# Check if the column exists\n",
        "train_data_clean.select(\"log_cost_12oz\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oTKcwdMkcxVk"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=[\n",
        "    'log_cost_12oz',\n",
        "    'aroma',\n",
        "    'acid',\n",
        "    'body',\n",
        "    'flavor',\n",
        "    'aftertaste',\n",
        "    'roaster_vec',\n",
        "    'origin_vec',\n",
        "    'roast_vec',\n",
        "    'aroma_acid',\n",
        "    'aroma_body',\n",
        "    'acid_body'\n",
        "], outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HQYwGo3czrP",
        "outputId": "6817b75a-104e-49b5-8efa-5e8385d5df7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE on test data with advanced feature engineering and cross-validation: 0.24428841078670538\n"
          ]
        }
      ],
      "source": [
        "# Define the RandomForestRegressor\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"rating\")\n",
        "\n",
        "# Create the pipeline with the new feature set\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, rf])\n",
        "\n",
        "# Run cross-validation\n",
        "cvModel = crossval.fit(train_data_clean)\n",
        "\n",
        "# Evaluate the best model\n",
        "bestModel = cvModel.bestModel\n",
        "predictions = bestModel.transform(test_data_clean)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Best RMSE on test data with advanced feature engineering and cross-validation: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3DkP2V3vDBb",
        "outputId": "d8f40e67-391a-4203-92e2-2de24fa9adb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results logged successfully.\n"
          ]
        }
      ],
      "source": [
        "# Ensure accessing the correct stage\n",
        "rf_model_stage = bestModel.stages[-1]\n",
        "\n",
        "# Extract the parameter map from the best model stage\n",
        "best_params = rf_model_stage.extractParamMap()\n",
        "\n",
        "# access parameters using .get() to avoid KeyErrors\n",
        "num_trees = best_params.get(rf.numTrees, \"Not Set\")\n",
        "max_depth = best_params.get(rf.maxDepth, \"Not Set\")\n",
        "max_bins = best_params.get(rf.maxBins, \"Not Set\")\n",
        "min_instances = best_params.get(rf.minInstancesPerNode, \"Not Set\")\n",
        "\n",
        "# Prepare the result dictionary\n",
        "result = {\n",
        "    \"numTrees\": num_trees,\n",
        "    \"maxDepth\": max_depth,\n",
        "    \"maxBins\": max_bins,\n",
        "    \"minInstancesPerNode\": min_instances,\n",
        "    \"RMSE\": rmse_simple,\n",
        "    \"Features\": \"cost_12oz, aroma, acid, body, flavor, aftertaste, roaster_vec, origin_vec, roast_vec\"\n",
        "}\n",
        "\n",
        "# Convert to DataFrame for logging\n",
        "result_df = pd.DataFrame([result])\n",
        "\n",
        "# Append or save the result to the CSV\n",
        "result_df.to_csv(\"model_results.csv\", mode='a', header=not os.path.exists(\"model_results.csv\"), index=False)\n",
        "\n",
        "print(\"Results logged successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ7-_csUci9c",
        "outputId": "ac92386e-506e-4895-bded-04bdd20e09a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE on test data with advanced feature engineering and cross-validation: 0.21023411898273872\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Define the parameter grid again\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [50, 100, 150])\n",
        "             .addGrid(rf.maxDepth, [5, 10, 15])\n",
        "             .addGrid(rf.maxBins, [32, 64])\n",
        "             .addGrid(rf.minInstancesPerNode, [1, 2])\n",
        "             .build())\n",
        "\n",
        "# Set up the cross-validator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
        "                          numFolds=3)  # 3-fold cross-validation\n",
        "\n",
        "# Run cross-validation\n",
        "cvModel = crossval.fit(train_data_clean)\n",
        "\n",
        "# Evaluate the best model\n",
        "bestModel = cvModel.bestModel\n",
        "predictions = bestModel.transform(test_data_clean)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Best RMSE on test data with advanced feature engineering and cross-validation: {rmse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic0L1lpLpKcV",
        "outputId": "6235d945-144f-48d8-cc50-aa6850e2913f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results have been saved to model_tuning_results.csv\n"
          ]
        }
      ],
      "source": [
        "# After the model evaluation\n",
        "import csv\n",
        "\n",
        "# Log the results to a CSV file\n",
        "csv_file = 'model_tuning_results.csv'\n",
        "with open(csv_file, mode='a', newline='') as file:  # 'a' for append mode\n",
        "    writer = csv.DictWriter(file, fieldnames=[\"numTrees\", \"maxDepth\", \"maxBins\", \"minInstancesPerNode\", \"RMSE\"])\n",
        "\n",
        "    # Check if the file is empty, write the header\n",
        "    if file.tell() == 0:\n",
        "        writer.writeheader()\n",
        "\n",
        "    # Extract best model hyperparameters\n",
        "    best_params = bestModel.stages[-1].extractParamMap()\n",
        "    result = {\n",
        "        \"numTrees\": best_params[rf.numTrees],\n",
        "        \"maxDepth\": best_params[rf.maxDepth],\n",
        "        \"maxBins\": best_params[rf.maxBins],\n",
        "        \"minInstancesPerNode\": best_params[rf.minInstancesPerNode],\n",
        "        \"RMSE\": rmse\n",
        "    }\n",
        "    writer.writerow(result)\n",
        "\n",
        "print(f\"Results have been saved to {csv_file}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}